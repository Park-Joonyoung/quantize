{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c77b026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.fx.graph_module.GraphModule.__new__.<locals>.GraphModuleImpl'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6423/138390372.py:25: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  prepared = prepare_pt2e(ep, quantizer)\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_1) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_2) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_3) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_4) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_5) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_6) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_7) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_8) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_9) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_10) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_11) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_12) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_13) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_14) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_15) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_16) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_17) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_18) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_19) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_20) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_21) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_22) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_23) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_24) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_25) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_26) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_27) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_28) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_29) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_30) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_31) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_32) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_33) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_34) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_35) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_36) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_37) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_38) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_39) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_40) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_41) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_42) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_43) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_44) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_45) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_46) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_47) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_48) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_49) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_50) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/joonyoung/.pyenv/versions/edge/lib/python3.11/site-packages/torch/fx/graph.py:1264: UserWarning: erase_node(batch_norm_51) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/tmp/ipykernel_6423/138390372.py:30: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  quantized = convert_pt2e(prepared, fold_quantize=False)\n",
      "WARNING:root:Your model is converted in training mode. Please set the module in evaluation mode with `module.eval()` for better on-device performance and compatibility.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (features): Module(\n",
      "    (0): Module(\n",
      "      (0): Module()\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module()\n",
      "      )\n",
      "    )\n",
      "    (2): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (3): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (4): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (5): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (6): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (7): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (8): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (9): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (10): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (11): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (12): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (13): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (14): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (15): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (16): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (17): Module(\n",
      "      (conv): Module(\n",
      "        (0): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (1): Module(\n",
      "          (0): Module()\n",
      "        )\n",
      "        (2): Module()\n",
      "      )\n",
      "    )\n",
      "    (18): Module(\n",
      "      (0): Module()\n",
      "    )\n",
      "  )\n",
      "  (classifier): Module(\n",
      "    (1): Module()\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
      "    features_0_0_weight = getattr(getattr(self.features, \"0\"), \"0\").weight\n",
      "    _scale_0 = self._scale_0\n",
      "    _zero_point_0 = self._zero_point_0\n",
      "    quantize_per_channel_default = torch.ops.quantized_decomposed.quantize_per_channel.default(features_0_0_weight, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  features_0_0_weight = None\n",
      "    dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None\n",
      "    features_1_conv_0_0_weight = getattr(getattr(getattr(self.features, \"1\").conv, \"0\"), \"0\").weight\n",
      "    _scale_1 = self._scale_1\n",
      "    _zero_point_1 = self._zero_point_1\n",
      "    quantize_per_channel_default_1 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_1_conv_0_0_weight, _scale_1, _zero_point_1, 0, -127, 127, torch.int8);  features_1_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_1 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_1, _scale_1, _zero_point_1, 0, -127, 127, torch.int8);  quantize_per_channel_default_1 = _scale_1 = _zero_point_1 = None\n",
      "    features_1_conv_1_weight = getattr(getattr(self.features, \"1\").conv, \"1\").weight\n",
      "    _scale_2 = self._scale_2\n",
      "    _zero_point_2 = self._zero_point_2\n",
      "    quantize_per_channel_default_2 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_1_conv_1_weight, _scale_2, _zero_point_2, 0, -127, 127, torch.int8);  features_1_conv_1_weight = None\n",
      "    dequantize_per_channel_default_2 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_2, _scale_2, _zero_point_2, 0, -127, 127, torch.int8);  quantize_per_channel_default_2 = _scale_2 = _zero_point_2 = None\n",
      "    features_2_conv_0_0_weight = getattr(getattr(getattr(self.features, \"2\").conv, \"0\"), \"0\").weight\n",
      "    _scale_3 = self._scale_3\n",
      "    _zero_point_3 = self._zero_point_3\n",
      "    quantize_per_channel_default_3 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_2_conv_0_0_weight, _scale_3, _zero_point_3, 0, -127, 127, torch.int8);  features_2_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_3 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_3, _scale_3, _zero_point_3, 0, -127, 127, torch.int8);  quantize_per_channel_default_3 = _scale_3 = _zero_point_3 = None\n",
      "    features_2_conv_1_0_weight = getattr(getattr(getattr(self.features, \"2\").conv, \"1\"), \"0\").weight\n",
      "    _scale_4 = self._scale_4\n",
      "    _zero_point_4 = self._zero_point_4\n",
      "    quantize_per_channel_default_4 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_2_conv_1_0_weight, _scale_4, _zero_point_4, 0, -127, 127, torch.int8);  features_2_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_4 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_4, _scale_4, _zero_point_4, 0, -127, 127, torch.int8);  quantize_per_channel_default_4 = _scale_4 = _zero_point_4 = None\n",
      "    features_2_conv_2_weight = getattr(getattr(self.features, \"2\").conv, \"2\").weight\n",
      "    _scale_5 = self._scale_5\n",
      "    _zero_point_5 = self._zero_point_5\n",
      "    quantize_per_channel_default_5 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_2_conv_2_weight, _scale_5, _zero_point_5, 0, -127, 127, torch.int8);  features_2_conv_2_weight = None\n",
      "    dequantize_per_channel_default_5 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_5, _scale_5, _zero_point_5, 0, -127, 127, torch.int8);  quantize_per_channel_default_5 = _scale_5 = _zero_point_5 = None\n",
      "    features_3_conv_0_0_weight = getattr(getattr(getattr(self.features, \"3\").conv, \"0\"), \"0\").weight\n",
      "    _scale_6 = self._scale_6\n",
      "    _zero_point_6 = self._zero_point_6\n",
      "    quantize_per_channel_default_6 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_3_conv_0_0_weight, _scale_6, _zero_point_6, 0, -127, 127, torch.int8);  features_3_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_6 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_6, _scale_6, _zero_point_6, 0, -127, 127, torch.int8);  quantize_per_channel_default_6 = _scale_6 = _zero_point_6 = None\n",
      "    features_3_conv_1_0_weight = getattr(getattr(getattr(self.features, \"3\").conv, \"1\"), \"0\").weight\n",
      "    _scale_7 = self._scale_7\n",
      "    _zero_point_7 = self._zero_point_7\n",
      "    quantize_per_channel_default_7 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_3_conv_1_0_weight, _scale_7, _zero_point_7, 0, -127, 127, torch.int8);  features_3_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_7 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_7, _scale_7, _zero_point_7, 0, -127, 127, torch.int8);  quantize_per_channel_default_7 = _scale_7 = _zero_point_7 = None\n",
      "    features_3_conv_2_weight = getattr(getattr(self.features, \"3\").conv, \"2\").weight\n",
      "    _scale_8 = self._scale_8\n",
      "    _zero_point_8 = self._zero_point_8\n",
      "    quantize_per_channel_default_8 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_3_conv_2_weight, _scale_8, _zero_point_8, 0, -127, 127, torch.int8);  features_3_conv_2_weight = None\n",
      "    dequantize_per_channel_default_8 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_8, _scale_8, _zero_point_8, 0, -127, 127, torch.int8);  quantize_per_channel_default_8 = _scale_8 = _zero_point_8 = None\n",
      "    features_4_conv_0_0_weight = getattr(getattr(getattr(self.features, \"4\").conv, \"0\"), \"0\").weight\n",
      "    _scale_9 = self._scale_9\n",
      "    _zero_point_9 = self._zero_point_9\n",
      "    quantize_per_channel_default_9 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_4_conv_0_0_weight, _scale_9, _zero_point_9, 0, -127, 127, torch.int8);  features_4_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_9 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_9, _scale_9, _zero_point_9, 0, -127, 127, torch.int8);  quantize_per_channel_default_9 = _scale_9 = _zero_point_9 = None\n",
      "    features_4_conv_1_0_weight = getattr(getattr(getattr(self.features, \"4\").conv, \"1\"), \"0\").weight\n",
      "    _scale_10 = self._scale_10\n",
      "    _zero_point_10 = self._zero_point_10\n",
      "    quantize_per_channel_default_10 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_4_conv_1_0_weight, _scale_10, _zero_point_10, 0, -127, 127, torch.int8);  features_4_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_10 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_10, _scale_10, _zero_point_10, 0, -127, 127, torch.int8);  quantize_per_channel_default_10 = _scale_10 = _zero_point_10 = None\n",
      "    features_4_conv_2_weight = getattr(getattr(self.features, \"4\").conv, \"2\").weight\n",
      "    _scale_11 = self._scale_11\n",
      "    _zero_point_11 = self._zero_point_11\n",
      "    quantize_per_channel_default_11 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_4_conv_2_weight, _scale_11, _zero_point_11, 0, -127, 127, torch.int8);  features_4_conv_2_weight = None\n",
      "    dequantize_per_channel_default_11 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_11, _scale_11, _zero_point_11, 0, -127, 127, torch.int8);  quantize_per_channel_default_11 = _scale_11 = _zero_point_11 = None\n",
      "    features_5_conv_0_0_weight = getattr(getattr(getattr(self.features, \"5\").conv, \"0\"), \"0\").weight\n",
      "    _scale_12 = self._scale_12\n",
      "    _zero_point_12 = self._zero_point_12\n",
      "    quantize_per_channel_default_12 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_5_conv_0_0_weight, _scale_12, _zero_point_12, 0, -127, 127, torch.int8);  features_5_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_12 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_12, _scale_12, _zero_point_12, 0, -127, 127, torch.int8);  quantize_per_channel_default_12 = _scale_12 = _zero_point_12 = None\n",
      "    features_5_conv_1_0_weight = getattr(getattr(getattr(self.features, \"5\").conv, \"1\"), \"0\").weight\n",
      "    _scale_13 = self._scale_13\n",
      "    _zero_point_13 = self._zero_point_13\n",
      "    quantize_per_channel_default_13 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_5_conv_1_0_weight, _scale_13, _zero_point_13, 0, -127, 127, torch.int8);  features_5_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_13 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_13, _scale_13, _zero_point_13, 0, -127, 127, torch.int8);  quantize_per_channel_default_13 = _scale_13 = _zero_point_13 = None\n",
      "    features_5_conv_2_weight = getattr(getattr(self.features, \"5\").conv, \"2\").weight\n",
      "    _scale_14 = self._scale_14\n",
      "    _zero_point_14 = self._zero_point_14\n",
      "    quantize_per_channel_default_14 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_5_conv_2_weight, _scale_14, _zero_point_14, 0, -127, 127, torch.int8);  features_5_conv_2_weight = None\n",
      "    dequantize_per_channel_default_14 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_14, _scale_14, _zero_point_14, 0, -127, 127, torch.int8);  quantize_per_channel_default_14 = _scale_14 = _zero_point_14 = None\n",
      "    features_6_conv_0_0_weight = getattr(getattr(getattr(self.features, \"6\").conv, \"0\"), \"0\").weight\n",
      "    _scale_15 = self._scale_15\n",
      "    _zero_point_15 = self._zero_point_15\n",
      "    quantize_per_channel_default_15 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_6_conv_0_0_weight, _scale_15, _zero_point_15, 0, -127, 127, torch.int8);  features_6_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_15 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_15, _scale_15, _zero_point_15, 0, -127, 127, torch.int8);  quantize_per_channel_default_15 = _scale_15 = _zero_point_15 = None\n",
      "    features_6_conv_1_0_weight = getattr(getattr(getattr(self.features, \"6\").conv, \"1\"), \"0\").weight\n",
      "    _scale_16 = self._scale_16\n",
      "    _zero_point_16 = self._zero_point_16\n",
      "    quantize_per_channel_default_16 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_6_conv_1_0_weight, _scale_16, _zero_point_16, 0, -127, 127, torch.int8);  features_6_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_16 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_16, _scale_16, _zero_point_16, 0, -127, 127, torch.int8);  quantize_per_channel_default_16 = _scale_16 = _zero_point_16 = None\n",
      "    features_6_conv_2_weight = getattr(getattr(self.features, \"6\").conv, \"2\").weight\n",
      "    _scale_17 = self._scale_17\n",
      "    _zero_point_17 = self._zero_point_17\n",
      "    quantize_per_channel_default_17 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_6_conv_2_weight, _scale_17, _zero_point_17, 0, -127, 127, torch.int8);  features_6_conv_2_weight = None\n",
      "    dequantize_per_channel_default_17 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_17, _scale_17, _zero_point_17, 0, -127, 127, torch.int8);  quantize_per_channel_default_17 = _scale_17 = _zero_point_17 = None\n",
      "    features_7_conv_0_0_weight = getattr(getattr(getattr(self.features, \"7\").conv, \"0\"), \"0\").weight\n",
      "    _scale_18 = self._scale_18\n",
      "    _zero_point_18 = self._zero_point_18\n",
      "    quantize_per_channel_default_18 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_7_conv_0_0_weight, _scale_18, _zero_point_18, 0, -127, 127, torch.int8);  features_7_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_18 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_18, _scale_18, _zero_point_18, 0, -127, 127, torch.int8);  quantize_per_channel_default_18 = _scale_18 = _zero_point_18 = None\n",
      "    features_7_conv_1_0_weight = getattr(getattr(getattr(self.features, \"7\").conv, \"1\"), \"0\").weight\n",
      "    _scale_19 = self._scale_19\n",
      "    _zero_point_19 = self._zero_point_19\n",
      "    quantize_per_channel_default_19 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_7_conv_1_0_weight, _scale_19, _zero_point_19, 0, -127, 127, torch.int8);  features_7_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_19 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_19, _scale_19, _zero_point_19, 0, -127, 127, torch.int8);  quantize_per_channel_default_19 = _scale_19 = _zero_point_19 = None\n",
      "    features_7_conv_2_weight = getattr(getattr(self.features, \"7\").conv, \"2\").weight\n",
      "    _scale_20 = self._scale_20\n",
      "    _zero_point_20 = self._zero_point_20\n",
      "    quantize_per_channel_default_20 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_7_conv_2_weight, _scale_20, _zero_point_20, 0, -127, 127, torch.int8);  features_7_conv_2_weight = None\n",
      "    dequantize_per_channel_default_20 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_20, _scale_20, _zero_point_20, 0, -127, 127, torch.int8);  quantize_per_channel_default_20 = _scale_20 = _zero_point_20 = None\n",
      "    features_8_conv_0_0_weight = getattr(getattr(getattr(self.features, \"8\").conv, \"0\"), \"0\").weight\n",
      "    _scale_21 = self._scale_21\n",
      "    _zero_point_21 = self._zero_point_21\n",
      "    quantize_per_channel_default_21 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_8_conv_0_0_weight, _scale_21, _zero_point_21, 0, -127, 127, torch.int8);  features_8_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_21 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_21, _scale_21, _zero_point_21, 0, -127, 127, torch.int8);  quantize_per_channel_default_21 = _scale_21 = _zero_point_21 = None\n",
      "    features_8_conv_1_0_weight = getattr(getattr(getattr(self.features, \"8\").conv, \"1\"), \"0\").weight\n",
      "    _scale_22 = self._scale_22\n",
      "    _zero_point_22 = self._zero_point_22\n",
      "    quantize_per_channel_default_22 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_8_conv_1_0_weight, _scale_22, _zero_point_22, 0, -127, 127, torch.int8);  features_8_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_22 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_22, _scale_22, _zero_point_22, 0, -127, 127, torch.int8);  quantize_per_channel_default_22 = _scale_22 = _zero_point_22 = None\n",
      "    features_8_conv_2_weight = getattr(getattr(self.features, \"8\").conv, \"2\").weight\n",
      "    _scale_23 = self._scale_23\n",
      "    _zero_point_23 = self._zero_point_23\n",
      "    quantize_per_channel_default_23 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_8_conv_2_weight, _scale_23, _zero_point_23, 0, -127, 127, torch.int8);  features_8_conv_2_weight = None\n",
      "    dequantize_per_channel_default_23 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_23, _scale_23, _zero_point_23, 0, -127, 127, torch.int8);  quantize_per_channel_default_23 = _scale_23 = _zero_point_23 = None\n",
      "    features_9_conv_0_0_weight = getattr(getattr(getattr(self.features, \"9\").conv, \"0\"), \"0\").weight\n",
      "    _scale_24 = self._scale_24\n",
      "    _zero_point_24 = self._zero_point_24\n",
      "    quantize_per_channel_default_24 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_9_conv_0_0_weight, _scale_24, _zero_point_24, 0, -127, 127, torch.int8);  features_9_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_24 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_24, _scale_24, _zero_point_24, 0, -127, 127, torch.int8);  quantize_per_channel_default_24 = _scale_24 = _zero_point_24 = None\n",
      "    features_9_conv_1_0_weight = getattr(getattr(getattr(self.features, \"9\").conv, \"1\"), \"0\").weight\n",
      "    _scale_25 = self._scale_25\n",
      "    _zero_point_25 = self._zero_point_25\n",
      "    quantize_per_channel_default_25 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_9_conv_1_0_weight, _scale_25, _zero_point_25, 0, -127, 127, torch.int8);  features_9_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_25 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_25, _scale_25, _zero_point_25, 0, -127, 127, torch.int8);  quantize_per_channel_default_25 = _scale_25 = _zero_point_25 = None\n",
      "    features_9_conv_2_weight = getattr(getattr(self.features, \"9\").conv, \"2\").weight\n",
      "    _scale_26 = self._scale_26\n",
      "    _zero_point_26 = self._zero_point_26\n",
      "    quantize_per_channel_default_26 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_9_conv_2_weight, _scale_26, _zero_point_26, 0, -127, 127, torch.int8);  features_9_conv_2_weight = None\n",
      "    dequantize_per_channel_default_26 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_26, _scale_26, _zero_point_26, 0, -127, 127, torch.int8);  quantize_per_channel_default_26 = _scale_26 = _zero_point_26 = None\n",
      "    features_10_conv_0_0_weight = getattr(getattr(getattr(self.features, \"10\").conv, \"0\"), \"0\").weight\n",
      "    _scale_27 = self._scale_27\n",
      "    _zero_point_27 = self._zero_point_27\n",
      "    quantize_per_channel_default_27 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_10_conv_0_0_weight, _scale_27, _zero_point_27, 0, -127, 127, torch.int8);  features_10_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_27 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_27, _scale_27, _zero_point_27, 0, -127, 127, torch.int8);  quantize_per_channel_default_27 = _scale_27 = _zero_point_27 = None\n",
      "    features_10_conv_1_0_weight = getattr(getattr(getattr(self.features, \"10\").conv, \"1\"), \"0\").weight\n",
      "    _scale_28 = self._scale_28\n",
      "    _zero_point_28 = self._zero_point_28\n",
      "    quantize_per_channel_default_28 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_10_conv_1_0_weight, _scale_28, _zero_point_28, 0, -127, 127, torch.int8);  features_10_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_28 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_28, _scale_28, _zero_point_28, 0, -127, 127, torch.int8);  quantize_per_channel_default_28 = _scale_28 = _zero_point_28 = None\n",
      "    features_10_conv_2_weight = getattr(getattr(self.features, \"10\").conv, \"2\").weight\n",
      "    _scale_29 = self._scale_29\n",
      "    _zero_point_29 = self._zero_point_29\n",
      "    quantize_per_channel_default_29 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_10_conv_2_weight, _scale_29, _zero_point_29, 0, -127, 127, torch.int8);  features_10_conv_2_weight = None\n",
      "    dequantize_per_channel_default_29 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_29, _scale_29, _zero_point_29, 0, -127, 127, torch.int8);  quantize_per_channel_default_29 = _scale_29 = _zero_point_29 = None\n",
      "    features_11_conv_0_0_weight = getattr(getattr(getattr(self.features, \"11\").conv, \"0\"), \"0\").weight\n",
      "    _scale_30 = self._scale_30\n",
      "    _zero_point_30 = self._zero_point_30\n",
      "    quantize_per_channel_default_30 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_11_conv_0_0_weight, _scale_30, _zero_point_30, 0, -127, 127, torch.int8);  features_11_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_30 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_30, _scale_30, _zero_point_30, 0, -127, 127, torch.int8);  quantize_per_channel_default_30 = _scale_30 = _zero_point_30 = None\n",
      "    features_11_conv_1_0_weight = getattr(getattr(getattr(self.features, \"11\").conv, \"1\"), \"0\").weight\n",
      "    _scale_31 = self._scale_31\n",
      "    _zero_point_31 = self._zero_point_31\n",
      "    quantize_per_channel_default_31 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_11_conv_1_0_weight, _scale_31, _zero_point_31, 0, -127, 127, torch.int8);  features_11_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_31 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_31, _scale_31, _zero_point_31, 0, -127, 127, torch.int8);  quantize_per_channel_default_31 = _scale_31 = _zero_point_31 = None\n",
      "    features_11_conv_2_weight = getattr(getattr(self.features, \"11\").conv, \"2\").weight\n",
      "    _scale_32 = self._scale_32\n",
      "    _zero_point_32 = self._zero_point_32\n",
      "    quantize_per_channel_default_32 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_11_conv_2_weight, _scale_32, _zero_point_32, 0, -127, 127, torch.int8);  features_11_conv_2_weight = None\n",
      "    dequantize_per_channel_default_32 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_32, _scale_32, _zero_point_32, 0, -127, 127, torch.int8);  quantize_per_channel_default_32 = _scale_32 = _zero_point_32 = None\n",
      "    features_12_conv_0_0_weight = getattr(getattr(getattr(self.features, \"12\").conv, \"0\"), \"0\").weight\n",
      "    _scale_33 = self._scale_33\n",
      "    _zero_point_33 = self._zero_point_33\n",
      "    quantize_per_channel_default_33 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_12_conv_0_0_weight, _scale_33, _zero_point_33, 0, -127, 127, torch.int8);  features_12_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_33 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_33, _scale_33, _zero_point_33, 0, -127, 127, torch.int8);  quantize_per_channel_default_33 = _scale_33 = _zero_point_33 = None\n",
      "    features_12_conv_1_0_weight = getattr(getattr(getattr(self.features, \"12\").conv, \"1\"), \"0\").weight\n",
      "    _scale_34 = self._scale_34\n",
      "    _zero_point_34 = self._zero_point_34\n",
      "    quantize_per_channel_default_34 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_12_conv_1_0_weight, _scale_34, _zero_point_34, 0, -127, 127, torch.int8);  features_12_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_34 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_34, _scale_34, _zero_point_34, 0, -127, 127, torch.int8);  quantize_per_channel_default_34 = _scale_34 = _zero_point_34 = None\n",
      "    features_12_conv_2_weight = getattr(getattr(self.features, \"12\").conv, \"2\").weight\n",
      "    _scale_35 = self._scale_35\n",
      "    _zero_point_35 = self._zero_point_35\n",
      "    quantize_per_channel_default_35 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_12_conv_2_weight, _scale_35, _zero_point_35, 0, -127, 127, torch.int8);  features_12_conv_2_weight = None\n",
      "    dequantize_per_channel_default_35 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_35, _scale_35, _zero_point_35, 0, -127, 127, torch.int8);  quantize_per_channel_default_35 = _scale_35 = _zero_point_35 = None\n",
      "    features_13_conv_0_0_weight = getattr(getattr(getattr(self.features, \"13\").conv, \"0\"), \"0\").weight\n",
      "    _scale_36 = self._scale_36\n",
      "    _zero_point_36 = self._zero_point_36\n",
      "    quantize_per_channel_default_36 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_13_conv_0_0_weight, _scale_36, _zero_point_36, 0, -127, 127, torch.int8);  features_13_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_36 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_36, _scale_36, _zero_point_36, 0, -127, 127, torch.int8);  quantize_per_channel_default_36 = _scale_36 = _zero_point_36 = None\n",
      "    features_13_conv_1_0_weight = getattr(getattr(getattr(self.features, \"13\").conv, \"1\"), \"0\").weight\n",
      "    _scale_37 = self._scale_37\n",
      "    _zero_point_37 = self._zero_point_37\n",
      "    quantize_per_channel_default_37 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_13_conv_1_0_weight, _scale_37, _zero_point_37, 0, -127, 127, torch.int8);  features_13_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_37 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_37, _scale_37, _zero_point_37, 0, -127, 127, torch.int8);  quantize_per_channel_default_37 = _scale_37 = _zero_point_37 = None\n",
      "    features_13_conv_2_weight = getattr(getattr(self.features, \"13\").conv, \"2\").weight\n",
      "    _scale_38 = self._scale_38\n",
      "    _zero_point_38 = self._zero_point_38\n",
      "    quantize_per_channel_default_38 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_13_conv_2_weight, _scale_38, _zero_point_38, 0, -127, 127, torch.int8);  features_13_conv_2_weight = None\n",
      "    dequantize_per_channel_default_38 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_38, _scale_38, _zero_point_38, 0, -127, 127, torch.int8);  quantize_per_channel_default_38 = _scale_38 = _zero_point_38 = None\n",
      "    features_14_conv_0_0_weight = getattr(getattr(getattr(self.features, \"14\").conv, \"0\"), \"0\").weight\n",
      "    _scale_39 = self._scale_39\n",
      "    _zero_point_39 = self._zero_point_39\n",
      "    quantize_per_channel_default_39 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_14_conv_0_0_weight, _scale_39, _zero_point_39, 0, -127, 127, torch.int8);  features_14_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_39 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_39, _scale_39, _zero_point_39, 0, -127, 127, torch.int8);  quantize_per_channel_default_39 = _scale_39 = _zero_point_39 = None\n",
      "    features_14_conv_1_0_weight = getattr(getattr(getattr(self.features, \"14\").conv, \"1\"), \"0\").weight\n",
      "    _scale_40 = self._scale_40\n",
      "    _zero_point_40 = self._zero_point_40\n",
      "    quantize_per_channel_default_40 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_14_conv_1_0_weight, _scale_40, _zero_point_40, 0, -127, 127, torch.int8);  features_14_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_40 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_40, _scale_40, _zero_point_40, 0, -127, 127, torch.int8);  quantize_per_channel_default_40 = _scale_40 = _zero_point_40 = None\n",
      "    features_14_conv_2_weight = getattr(getattr(self.features, \"14\").conv, \"2\").weight\n",
      "    _scale_41 = self._scale_41\n",
      "    _zero_point_41 = self._zero_point_41\n",
      "    quantize_per_channel_default_41 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_14_conv_2_weight, _scale_41, _zero_point_41, 0, -127, 127, torch.int8);  features_14_conv_2_weight = None\n",
      "    dequantize_per_channel_default_41 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_41, _scale_41, _zero_point_41, 0, -127, 127, torch.int8);  quantize_per_channel_default_41 = _scale_41 = _zero_point_41 = None\n",
      "    features_15_conv_0_0_weight = getattr(getattr(getattr(self.features, \"15\").conv, \"0\"), \"0\").weight\n",
      "    _scale_42 = self._scale_42\n",
      "    _zero_point_42 = self._zero_point_42\n",
      "    quantize_per_channel_default_42 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_15_conv_0_0_weight, _scale_42, _zero_point_42, 0, -127, 127, torch.int8);  features_15_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_42 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_42, _scale_42, _zero_point_42, 0, -127, 127, torch.int8);  quantize_per_channel_default_42 = _scale_42 = _zero_point_42 = None\n",
      "    features_15_conv_1_0_weight = getattr(getattr(getattr(self.features, \"15\").conv, \"1\"), \"0\").weight\n",
      "    _scale_43 = self._scale_43\n",
      "    _zero_point_43 = self._zero_point_43\n",
      "    quantize_per_channel_default_43 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_15_conv_1_0_weight, _scale_43, _zero_point_43, 0, -127, 127, torch.int8);  features_15_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_43 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_43, _scale_43, _zero_point_43, 0, -127, 127, torch.int8);  quantize_per_channel_default_43 = _scale_43 = _zero_point_43 = None\n",
      "    features_15_conv_2_weight = getattr(getattr(self.features, \"15\").conv, \"2\").weight\n",
      "    _scale_44 = self._scale_44\n",
      "    _zero_point_44 = self._zero_point_44\n",
      "    quantize_per_channel_default_44 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_15_conv_2_weight, _scale_44, _zero_point_44, 0, -127, 127, torch.int8);  features_15_conv_2_weight = None\n",
      "    dequantize_per_channel_default_44 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_44, _scale_44, _zero_point_44, 0, -127, 127, torch.int8);  quantize_per_channel_default_44 = _scale_44 = _zero_point_44 = None\n",
      "    features_16_conv_0_0_weight = getattr(getattr(getattr(self.features, \"16\").conv, \"0\"), \"0\").weight\n",
      "    _scale_45 = self._scale_45\n",
      "    _zero_point_45 = self._zero_point_45\n",
      "    quantize_per_channel_default_45 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_16_conv_0_0_weight, _scale_45, _zero_point_45, 0, -127, 127, torch.int8);  features_16_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_45 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_45, _scale_45, _zero_point_45, 0, -127, 127, torch.int8);  quantize_per_channel_default_45 = _scale_45 = _zero_point_45 = None\n",
      "    features_16_conv_1_0_weight = getattr(getattr(getattr(self.features, \"16\").conv, \"1\"), \"0\").weight\n",
      "    _scale_46 = self._scale_46\n",
      "    _zero_point_46 = self._zero_point_46\n",
      "    quantize_per_channel_default_46 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_16_conv_1_0_weight, _scale_46, _zero_point_46, 0, -127, 127, torch.int8);  features_16_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_46 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_46, _scale_46, _zero_point_46, 0, -127, 127, torch.int8);  quantize_per_channel_default_46 = _scale_46 = _zero_point_46 = None\n",
      "    features_16_conv_2_weight = getattr(getattr(self.features, \"16\").conv, \"2\").weight\n",
      "    _scale_47 = self._scale_47\n",
      "    _zero_point_47 = self._zero_point_47\n",
      "    quantize_per_channel_default_47 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_16_conv_2_weight, _scale_47, _zero_point_47, 0, -127, 127, torch.int8);  features_16_conv_2_weight = None\n",
      "    dequantize_per_channel_default_47 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_47, _scale_47, _zero_point_47, 0, -127, 127, torch.int8);  quantize_per_channel_default_47 = _scale_47 = _zero_point_47 = None\n",
      "    features_17_conv_0_0_weight = getattr(getattr(getattr(self.features, \"17\").conv, \"0\"), \"0\").weight\n",
      "    _scale_48 = self._scale_48\n",
      "    _zero_point_48 = self._zero_point_48\n",
      "    quantize_per_channel_default_48 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_17_conv_0_0_weight, _scale_48, _zero_point_48, 0, -127, 127, torch.int8);  features_17_conv_0_0_weight = None\n",
      "    dequantize_per_channel_default_48 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_48, _scale_48, _zero_point_48, 0, -127, 127, torch.int8);  quantize_per_channel_default_48 = _scale_48 = _zero_point_48 = None\n",
      "    features_17_conv_1_0_weight = getattr(getattr(getattr(self.features, \"17\").conv, \"1\"), \"0\").weight\n",
      "    _scale_49 = self._scale_49\n",
      "    _zero_point_49 = self._zero_point_49\n",
      "    quantize_per_channel_default_49 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_17_conv_1_0_weight, _scale_49, _zero_point_49, 0, -127, 127, torch.int8);  features_17_conv_1_0_weight = None\n",
      "    dequantize_per_channel_default_49 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_49, _scale_49, _zero_point_49, 0, -127, 127, torch.int8);  quantize_per_channel_default_49 = _scale_49 = _zero_point_49 = None\n",
      "    features_17_conv_2_weight = getattr(getattr(self.features, \"17\").conv, \"2\").weight\n",
      "    _scale_50 = self._scale_50\n",
      "    _zero_point_50 = self._zero_point_50\n",
      "    quantize_per_channel_default_50 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_17_conv_2_weight, _scale_50, _zero_point_50, 0, -127, 127, torch.int8);  features_17_conv_2_weight = None\n",
      "    dequantize_per_channel_default_50 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_50, _scale_50, _zero_point_50, 0, -127, 127, torch.int8);  quantize_per_channel_default_50 = _scale_50 = _zero_point_50 = None\n",
      "    features_18_0_weight = getattr(getattr(self.features, \"18\"), \"0\").weight\n",
      "    _scale_51 = self._scale_51\n",
      "    _zero_point_51 = self._zero_point_51\n",
      "    quantize_per_channel_default_51 = torch.ops.quantized_decomposed.quantize_per_channel.default(features_18_0_weight, _scale_51, _zero_point_51, 0, -127, 127, torch.int8);  features_18_0_weight = None\n",
      "    dequantize_per_channel_default_51 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_51, _scale_51, _zero_point_51, 0, -127, 127, torch.int8);  quantize_per_channel_default_51 = _scale_51 = _zero_point_51 = None\n",
      "    classifier_1_weight = getattr(self.classifier, \"1\").weight\n",
      "    _scale_52 = self._scale_52\n",
      "    _zero_point_52 = self._zero_point_52\n",
      "    quantize_per_channel_default_52 = torch.ops.quantized_decomposed.quantize_per_channel.default(classifier_1_weight, _scale_52, _zero_point_52, 0, -127, 127, torch.int8);  classifier_1_weight = None\n",
      "    dequantize_per_channel_default_52 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default_52, _scale_52, _zero_point_52, 0, -127, 127, torch.int8);  quantize_per_channel_default_52 = _scale_52 = _zero_point_52 = None\n",
      "    classifier_1_bias = getattr(self.classifier, \"1\").bias\n",
      "    quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.030688544735312462, -1, -128, 127, torch.int8);  x = None\n",
      "    dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.030688544735312462, -1, -128, 127, torch.int8);  quantize_per_tensor_default = None\n",
      "    features_0_0_weight_bias = getattr(getattr(self.features, \"0\"), \"0\").weight_bias\n",
      "    conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_default, features_0_0_weight_bias, [2, 2], [1, 1]);  dequantize_per_tensor_default = dequantize_per_channel_default = features_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.25043806433677673, -11, -128, 127, torch.int8);  conv2d = None\n",
      "    dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.25043806433677673, -11, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None\n",
      "    hardtanh_ = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_1, 0.0, 6.0);  dequantize_per_tensor_default_1 = None\n",
      "    quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh_, 0.25043806433677673, -11, -128, 127, torch.int8);  hardtanh_ = None\n",
      "    dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.25043806433677673, -11, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None\n",
      "    features_1_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"1\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_1 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_2, dequantize_per_channel_default_1, features_1_conv_0_0_weight_bias, [1, 1], [1, 1], [1, 1], 32);  dequantize_per_tensor_default_2 = dequantize_per_channel_default_1 = features_1_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_1, 0.3814573287963867, -8, -128, 127, torch.int8);  conv2d_1 = None\n",
      "    dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.3814573287963867, -8, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None\n",
      "    hardtanh__1 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_3, 0.0, 6.0);  dequantize_per_tensor_default_3 = None\n",
      "    quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__1, 0.3814573287963867, -8, -128, 127, torch.int8);  hardtanh__1 = None\n",
      "    dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.3814573287963867, -8, -128, 127, torch.int8);  quantize_per_tensor_default_4 = None\n",
      "    features_1_conv_1_weight_bias = getattr(getattr(self.features, \"1\").conv, \"1\").weight_bias\n",
      "    conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_4, dequantize_per_channel_default_2, features_1_conv_1_weight_bias);  dequantize_per_tensor_default_4 = dequantize_per_channel_default_2 = features_1_conv_1_weight_bias = None\n",
      "    quantize_per_tensor_default_5 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.5124295949935913, 20, -128, 127, torch.int8);  conv2d_2 = None\n",
      "    dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_5, 0.5124295949935913, 20, -128, 127, torch.int8);  quantize_per_tensor_default_5 = None\n",
      "    features_2_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"2\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_3 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_5, dequantize_per_channel_default_3, features_2_conv_0_0_weight_bias);  dequantize_per_tensor_default_5 = dequantize_per_channel_default_3 = features_2_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_6 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_3, 0.3699303865432739, -11, -128, 127, torch.int8);  conv2d_3 = None\n",
      "    dequantize_per_tensor_default_6 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_6, 0.3699303865432739, -11, -128, 127, torch.int8);  quantize_per_tensor_default_6 = None\n",
      "    hardtanh__2 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_6, 0.0, 6.0);  dequantize_per_tensor_default_6 = None\n",
      "    quantize_per_tensor_default_7 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__2, 0.3699303865432739, -11, -128, 127, torch.int8);  hardtanh__2 = None\n",
      "    dequantize_per_tensor_default_7 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_7, 0.3699303865432739, -11, -128, 127, torch.int8);  quantize_per_tensor_default_7 = None\n",
      "    features_2_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"2\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_7, dequantize_per_channel_default_4, features_2_conv_1_0_weight_bias, [2, 2], [1, 1], [1, 1], 96);  dequantize_per_tensor_default_7 = dequantize_per_channel_default_4 = features_2_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_8 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.11371229588985443, 28, -128, 127, torch.int8);  conv2d_4 = None\n",
      "    dequantize_per_tensor_default_8 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_8, 0.11371229588985443, 28, -128, 127, torch.int8);  quantize_per_tensor_default_8 = None\n",
      "    hardtanh__3 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_8, 0.0, 6.0);  dequantize_per_tensor_default_8 = None\n",
      "    quantize_per_tensor_default_9 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__3, 0.11371229588985443, 28, -128, 127, torch.int8);  hardtanh__3 = None\n",
      "    dequantize_per_tensor_default_9 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_9, 0.11371229588985443, 28, -128, 127, torch.int8);  quantize_per_tensor_default_9 = None\n",
      "    features_2_conv_2_weight_bias = getattr(getattr(self.features, \"2\").conv, \"2\").weight_bias\n",
      "    conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_9, dequantize_per_channel_default_5, features_2_conv_2_weight_bias);  dequantize_per_tensor_default_9 = dequantize_per_channel_default_5 = features_2_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_10 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_5, 0.32883355021476746, 2, -128, 127, torch.int8);  conv2d_5 = None\n",
      "    dequantize_per_tensor_default_10 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_10, 0.32883355021476746, 2, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_102 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_10, 0.32883355021476746, 2, -128, 127, torch.int8);  quantize_per_tensor_default_10 = None\n",
      "    features_3_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"3\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_6 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_102, dequantize_per_channel_default_6, features_3_conv_0_0_weight_bias);  dequantize_per_tensor_default_102 = dequantize_per_channel_default_6 = features_3_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_11 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_6, 0.1671539694070816, 6, -128, 127, torch.int8);  conv2d_6 = None\n",
      "    dequantize_per_tensor_default_11 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_11, 0.1671539694070816, 6, -128, 127, torch.int8);  quantize_per_tensor_default_11 = None\n",
      "    hardtanh__4 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_11, 0.0, 6.0);  dequantize_per_tensor_default_11 = None\n",
      "    quantize_per_tensor_default_12 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__4, 0.1671539694070816, 6, -128, 127, torch.int8);  hardtanh__4 = None\n",
      "    dequantize_per_tensor_default_12 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_12, 0.1671539694070816, 6, -128, 127, torch.int8);  quantize_per_tensor_default_12 = None\n",
      "    features_3_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"3\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_7 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_12, dequantize_per_channel_default_7, features_3_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 144);  dequantize_per_tensor_default_12 = dequantize_per_channel_default_7 = features_3_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_13 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_7, 0.1579434871673584, 40, -128, 127, torch.int8);  conv2d_7 = None\n",
      "    dequantize_per_tensor_default_13 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_13, 0.1579434871673584, 40, -128, 127, torch.int8);  quantize_per_tensor_default_13 = None\n",
      "    hardtanh__5 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_13, 0.0, 6.0);  dequantize_per_tensor_default_13 = None\n",
      "    quantize_per_tensor_default_14 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__5, 0.1579434871673584, 40, -128, 127, torch.int8);  hardtanh__5 = None\n",
      "    dequantize_per_tensor_default_14 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_14, 0.1579434871673584, 40, -128, 127, torch.int8);  quantize_per_tensor_default_14 = None\n",
      "    features_3_conv_2_weight_bias = getattr(getattr(self.features, \"3\").conv, \"2\").weight_bias\n",
      "    conv2d_8 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_14, dequantize_per_channel_default_8, features_3_conv_2_weight_bias);  dequantize_per_tensor_default_14 = dequantize_per_channel_default_8 = features_3_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_15 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_8, 0.33807557821273804, -1, -128, 127, torch.int8);  conv2d_8 = None\n",
      "    dequantize_per_tensor_default_15 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_15, 0.33807557821273804, -1, -128, 127, torch.int8);  quantize_per_tensor_default_15 = None\n",
      "    add = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_10, dequantize_per_tensor_default_15);  dequantize_per_tensor_default_10 = dequantize_per_tensor_default_15 = None\n",
      "    quantize_per_tensor_default_16 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add, 0.34901484847068787, 4, -128, 127, torch.int8);  add = None\n",
      "    dequantize_per_tensor_default_16 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_16, 0.34901484847068787, 4, -128, 127, torch.int8);  quantize_per_tensor_default_16 = None\n",
      "    features_4_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"4\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_9 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_16, dequantize_per_channel_default_9, features_4_conv_0_0_weight_bias);  dequantize_per_tensor_default_16 = dequantize_per_channel_default_9 = features_4_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_17 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_9, 0.17823737859725952, 0, -128, 127, torch.int8);  conv2d_9 = None\n",
      "    dequantize_per_tensor_default_17 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_17, 0.17823737859725952, 0, -128, 127, torch.int8);  quantize_per_tensor_default_17 = None\n",
      "    hardtanh__6 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_17, 0.0, 6.0);  dequantize_per_tensor_default_17 = None\n",
      "    quantize_per_tensor_default_18 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__6, 0.17823737859725952, 0, -128, 127, torch.int8);  hardtanh__6 = None\n",
      "    dequantize_per_tensor_default_18 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_18, 0.17823737859725952, 0, -128, 127, torch.int8);  quantize_per_tensor_default_18 = None\n",
      "    features_4_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"4\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_10 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_18, dequantize_per_channel_default_10, features_4_conv_1_0_weight_bias, [2, 2], [1, 1], [1, 1], 144);  dequantize_per_tensor_default_18 = dequantize_per_channel_default_10 = features_4_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_19 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_10, 0.07277931272983551, 3, -128, 127, torch.int8);  conv2d_10 = None\n",
      "    dequantize_per_tensor_default_19 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_19, 0.07277931272983551, 3, -128, 127, torch.int8);  quantize_per_tensor_default_19 = None\n",
      "    hardtanh__7 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_19, 0.0, 6.0);  dequantize_per_tensor_default_19 = None\n",
      "    quantize_per_tensor_default_20 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__7, 0.07277931272983551, 3, -128, 127, torch.int8);  hardtanh__7 = None\n",
      "    dequantize_per_tensor_default_20 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_20, 0.07277931272983551, 3, -128, 127, torch.int8);  quantize_per_tensor_default_20 = None\n",
      "    features_4_conv_2_weight_bias = getattr(getattr(self.features, \"4\").conv, \"2\").weight_bias\n",
      "    conv2d_11 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_20, dequantize_per_channel_default_11, features_4_conv_2_weight_bias);  dequantize_per_tensor_default_20 = dequantize_per_channel_default_11 = features_4_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_21 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_11, 0.16855517029762268, -8, -128, 127, torch.int8);  conv2d_11 = None\n",
      "    dequantize_per_tensor_default_21 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_21, 0.16855517029762268, -8, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_103 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_21, 0.16855517029762268, -8, -128, 127, torch.int8);  quantize_per_tensor_default_21 = None\n",
      "    features_5_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"5\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_12 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_103, dequantize_per_channel_default_12, features_5_conv_0_0_weight_bias);  dequantize_per_tensor_default_103 = dequantize_per_channel_default_12 = features_5_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_22 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_12, 0.05896303057670593, 9, -128, 127, torch.int8);  conv2d_12 = None\n",
      "    dequantize_per_tensor_default_22 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_22, 0.05896303057670593, 9, -128, 127, torch.int8);  quantize_per_tensor_default_22 = None\n",
      "    hardtanh__8 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_22, 0.0, 6.0);  dequantize_per_tensor_default_22 = None\n",
      "    quantize_per_tensor_default_23 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__8, 0.05896303057670593, 9, -128, 127, torch.int8);  hardtanh__8 = None\n",
      "    dequantize_per_tensor_default_23 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_23, 0.05896303057670593, 9, -128, 127, torch.int8);  quantize_per_tensor_default_23 = None\n",
      "    features_5_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"5\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_13 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_23, dequantize_per_channel_default_13, features_5_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 192);  dequantize_per_tensor_default_23 = dequantize_per_channel_default_13 = features_5_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_24 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_13, 0.06564103811979294, 30, -128, 127, torch.int8);  conv2d_13 = None\n",
      "    dequantize_per_tensor_default_24 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_24, 0.06564103811979294, 30, -128, 127, torch.int8);  quantize_per_tensor_default_24 = None\n",
      "    hardtanh__9 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_24, 0.0, 6.0);  dequantize_per_tensor_default_24 = None\n",
      "    quantize_per_tensor_default_25 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__9, 0.06564103811979294, 30, -128, 127, torch.int8);  hardtanh__9 = None\n",
      "    dequantize_per_tensor_default_25 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_25, 0.06564103811979294, 30, -128, 127, torch.int8);  quantize_per_tensor_default_25 = None\n",
      "    features_5_conv_2_weight_bias = getattr(getattr(self.features, \"5\").conv, \"2\").weight_bias\n",
      "    conv2d_14 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_25, dequantize_per_channel_default_14, features_5_conv_2_weight_bias);  dequantize_per_tensor_default_25 = dequantize_per_channel_default_14 = features_5_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_26 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_14, 0.1602400839328766, -8, -128, 127, torch.int8);  conv2d_14 = None\n",
      "    dequantize_per_tensor_default_26 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_26, 0.1602400839328766, -8, -128, 127, torch.int8);  quantize_per_tensor_default_26 = None\n",
      "    add_1 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_21, dequantize_per_tensor_default_26);  dequantize_per_tensor_default_21 = dequantize_per_tensor_default_26 = None\n",
      "    quantize_per_tensor_default_27 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_1, 0.1984330117702484, 3, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_27 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_27, 0.1984330117702484, 3, -128, 127, torch.int8);  quantize_per_tensor_default_27 = None\n",
      "    features_6_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"6\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_15 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_27, dequantize_per_channel_default_15, features_6_conv_0_0_weight_bias);  dequantize_per_tensor_default_27 = dequantize_per_channel_default_15 = features_6_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_28 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_15, 0.06579098105430603, 36, -128, 127, torch.int8);  conv2d_15 = None\n",
      "    dequantize_per_tensor_default_28 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_28, 0.06579098105430603, 36, -128, 127, torch.int8);  quantize_per_tensor_default_28 = None\n",
      "    hardtanh__10 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_28, 0.0, 6.0);  dequantize_per_tensor_default_28 = None\n",
      "    quantize_per_tensor_default_29 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__10, 0.06579098105430603, 36, -128, 127, torch.int8);  hardtanh__10 = None\n",
      "    dequantize_per_tensor_default_29 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_29, 0.06579098105430603, 36, -128, 127, torch.int8);  quantize_per_tensor_default_29 = None\n",
      "    features_6_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"6\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_16 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_29, dequantize_per_channel_default_16, features_6_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 192);  dequantize_per_tensor_default_29 = dequantize_per_channel_default_16 = features_6_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_30 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_16, 0.08226840943098068, 57, -128, 127, torch.int8);  conv2d_16 = None\n",
      "    dequantize_per_tensor_default_30 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_30, 0.08226840943098068, 57, -128, 127, torch.int8);  quantize_per_tensor_default_30 = None\n",
      "    hardtanh__11 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_30, 0.0, 6.0);  dequantize_per_tensor_default_30 = None\n",
      "    quantize_per_tensor_default_31 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__11, 0.08226840943098068, 57, -128, 127, torch.int8);  hardtanh__11 = None\n",
      "    dequantize_per_tensor_default_31 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_31, 0.08226840943098068, 57, -128, 127, torch.int8);  quantize_per_tensor_default_31 = None\n",
      "    features_6_conv_2_weight_bias = getattr(getattr(self.features, \"6\").conv, \"2\").weight_bias\n",
      "    conv2d_17 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_31, dequantize_per_channel_default_17, features_6_conv_2_weight_bias);  dequantize_per_tensor_default_31 = dequantize_per_channel_default_17 = features_6_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_32 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_17, 0.18736989796161652, 50, -128, 127, torch.int8);  conv2d_17 = None\n",
      "    dequantize_per_tensor_default_32 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_32, 0.18736989796161652, 50, -128, 127, torch.int8);  quantize_per_tensor_default_32 = None\n",
      "    add_2 = torch.ops.aten.add.Tensor(add_1, dequantize_per_tensor_default_32);  add_1 = dequantize_per_tensor_default_32 = None\n",
      "    quantize_per_tensor_default_33 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_2, 0.23434363305568695, 9, -128, 127, torch.int8);  add_2 = None\n",
      "    dequantize_per_tensor_default_33 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_33, 0.23434363305568695, 9, -128, 127, torch.int8);  quantize_per_tensor_default_33 = None\n",
      "    features_7_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"7\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_18 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_33, dequantize_per_channel_default_18, features_7_conv_0_0_weight_bias);  dequantize_per_tensor_default_33 = dequantize_per_channel_default_18 = features_7_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_34 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_18, 0.07248463481664658, 4, -128, 127, torch.int8);  conv2d_18 = None\n",
      "    dequantize_per_tensor_default_34 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_34, 0.07248463481664658, 4, -128, 127, torch.int8);  quantize_per_tensor_default_34 = None\n",
      "    hardtanh__12 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_34, 0.0, 6.0);  dequantize_per_tensor_default_34 = None\n",
      "    quantize_per_tensor_default_35 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__12, 0.07248463481664658, 4, -128, 127, torch.int8);  hardtanh__12 = None\n",
      "    dequantize_per_tensor_default_35 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_35, 0.07248463481664658, 4, -128, 127, torch.int8);  quantize_per_tensor_default_35 = None\n",
      "    features_7_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"7\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_19 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_35, dequantize_per_channel_default_19, features_7_conv_1_0_weight_bias, [2, 2], [1, 1], [1, 1], 192);  dequantize_per_tensor_default_35 = dequantize_per_channel_default_19 = features_7_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_36 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_19, 0.04040756821632385, -40, -128, 127, torch.int8);  conv2d_19 = None\n",
      "    dequantize_per_tensor_default_36 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_36, 0.04040756821632385, -40, -128, 127, torch.int8);  quantize_per_tensor_default_36 = None\n",
      "    hardtanh__13 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_36, 0.0, 6.0);  dequantize_per_tensor_default_36 = None\n",
      "    quantize_per_tensor_default_37 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__13, 0.04040756821632385, -40, -128, 127, torch.int8);  hardtanh__13 = None\n",
      "    dequantize_per_tensor_default_37 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_37, 0.04040756821632385, -40, -128, 127, torch.int8);  quantize_per_tensor_default_37 = None\n",
      "    features_7_conv_2_weight_bias = getattr(getattr(self.features, \"7\").conv, \"2\").weight_bias\n",
      "    conv2d_20 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_37, dequantize_per_channel_default_20, features_7_conv_2_weight_bias);  dequantize_per_tensor_default_37 = dequantize_per_channel_default_20 = features_7_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_38 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_20, 0.1141279935836792, -5, -128, 127, torch.int8);  conv2d_20 = None\n",
      "    dequantize_per_tensor_default_38 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_38, 0.1141279935836792, -5, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_104 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_38, 0.1141279935836792, -5, -128, 127, torch.int8);  quantize_per_tensor_default_38 = None\n",
      "    features_8_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"8\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_21 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_104, dequantize_per_channel_default_21, features_8_conv_0_0_weight_bias);  dequantize_per_tensor_default_104 = dequantize_per_channel_default_21 = features_8_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_39 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_21, 0.05610688775777817, 0, -128, 127, torch.int8);  conv2d_21 = None\n",
      "    dequantize_per_tensor_default_39 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_39, 0.05610688775777817, 0, -128, 127, torch.int8);  quantize_per_tensor_default_39 = None\n",
      "    hardtanh__14 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_39, 0.0, 6.0);  dequantize_per_tensor_default_39 = None\n",
      "    quantize_per_tensor_default_40 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__14, 0.05610688775777817, 0, -128, 127, torch.int8);  hardtanh__14 = None\n",
      "    dequantize_per_tensor_default_40 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_40, 0.05610688775777817, 0, -128, 127, torch.int8);  quantize_per_tensor_default_40 = None\n",
      "    features_8_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"8\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_22 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_40, dequantize_per_channel_default_22, features_8_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 384);  dequantize_per_tensor_default_40 = dequantize_per_channel_default_22 = features_8_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_41 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_22, 0.1514969766139984, 65, -128, 127, torch.int8);  conv2d_22 = None\n",
      "    dequantize_per_tensor_default_41 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_41, 0.1514969766139984, 65, -128, 127, torch.int8);  quantize_per_tensor_default_41 = None\n",
      "    hardtanh__15 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_41, 0.0, 6.0);  dequantize_per_tensor_default_41 = None\n",
      "    quantize_per_tensor_default_42 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__15, 0.1514969766139984, 65, -128, 127, torch.int8);  hardtanh__15 = None\n",
      "    dequantize_per_tensor_default_42 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_42, 0.1514969766139984, 65, -128, 127, torch.int8);  quantize_per_tensor_default_42 = None\n",
      "    features_8_conv_2_weight_bias = getattr(getattr(self.features, \"8\").conv, \"2\").weight_bias\n",
      "    conv2d_23 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_42, dequantize_per_channel_default_23, features_8_conv_2_weight_bias);  dequantize_per_tensor_default_42 = dequantize_per_channel_default_23 = features_8_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_43 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_23, 0.1292833387851715, -5, -128, 127, torch.int8);  conv2d_23 = None\n",
      "    dequantize_per_tensor_default_43 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_43, 0.1292833387851715, -5, -128, 127, torch.int8);  quantize_per_tensor_default_43 = None\n",
      "    add_3 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_38, dequantize_per_tensor_default_43);  dequantize_per_tensor_default_38 = dequantize_per_tensor_default_43 = None\n",
      "    quantize_per_tensor_default_44 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_3, 0.13104307651519775, -14, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_44 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_44, 0.13104307651519775, -14, -128, 127, torch.int8);  quantize_per_tensor_default_44 = None\n",
      "    features_9_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"9\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_24 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_44, dequantize_per_channel_default_24, features_9_conv_0_0_weight_bias);  dequantize_per_tensor_default_44 = dequantize_per_channel_default_24 = features_9_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_45 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_24, 0.05378320440649986, -8, -128, 127, torch.int8);  conv2d_24 = None\n",
      "    dequantize_per_tensor_default_45 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_45, 0.05378320440649986, -8, -128, 127, torch.int8);  quantize_per_tensor_default_45 = None\n",
      "    hardtanh__16 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_45, 0.0, 6.0);  dequantize_per_tensor_default_45 = None\n",
      "    quantize_per_tensor_default_46 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__16, 0.05378320440649986, -8, -128, 127, torch.int8);  hardtanh__16 = None\n",
      "    dequantize_per_tensor_default_46 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_46, 0.05378320440649986, -8, -128, 127, torch.int8);  quantize_per_tensor_default_46 = None\n",
      "    features_9_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"9\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_25 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_46, dequantize_per_channel_default_25, features_9_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 384);  dequantize_per_tensor_default_46 = dequantize_per_channel_default_25 = features_9_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_47 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_25, 0.08111646771430969, 56, -128, 127, torch.int8);  conv2d_25 = None\n",
      "    dequantize_per_tensor_default_47 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_47, 0.08111646771430969, 56, -128, 127, torch.int8);  quantize_per_tensor_default_47 = None\n",
      "    hardtanh__17 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_47, 0.0, 6.0);  dequantize_per_tensor_default_47 = None\n",
      "    quantize_per_tensor_default_48 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__17, 0.08111646771430969, 56, -128, 127, torch.int8);  hardtanh__17 = None\n",
      "    dequantize_per_tensor_default_48 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_48, 0.08111646771430969, 56, -128, 127, torch.int8);  quantize_per_tensor_default_48 = None\n",
      "    features_9_conv_2_weight_bias = getattr(getattr(self.features, \"9\").conv, \"2\").weight_bias\n",
      "    conv2d_26 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_48, dequantize_per_channel_default_26, features_9_conv_2_weight_bias);  dequantize_per_tensor_default_48 = dequantize_per_channel_default_26 = features_9_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_49 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_26, 0.09704110771417618, 9, -128, 127, torch.int8);  conv2d_26 = None\n",
      "    dequantize_per_tensor_default_49 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_49, 0.09704110771417618, 9, -128, 127, torch.int8);  quantize_per_tensor_default_49 = None\n",
      "    add_4 = torch.ops.aten.add.Tensor(add_3, dequantize_per_tensor_default_49);  add_3 = dequantize_per_tensor_default_49 = None\n",
      "    quantize_per_tensor_default_50 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_4, 0.1272606998682022, -11, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_50 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_50, 0.1272606998682022, -11, -128, 127, torch.int8);  quantize_per_tensor_default_50 = None\n",
      "    features_10_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"10\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_27 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_50, dequantize_per_channel_default_27, features_10_conv_0_0_weight_bias);  dequantize_per_tensor_default_50 = dequantize_per_channel_default_27 = features_10_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_51 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_27, 0.050029464066028595, 18, -128, 127, torch.int8);  conv2d_27 = None\n",
      "    dequantize_per_tensor_default_51 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_51, 0.050029464066028595, 18, -128, 127, torch.int8);  quantize_per_tensor_default_51 = None\n",
      "    hardtanh__18 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_51, 0.0, 6.0);  dequantize_per_tensor_default_51 = None\n",
      "    quantize_per_tensor_default_52 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__18, 0.050029464066028595, 18, -128, 127, torch.int8);  hardtanh__18 = None\n",
      "    dequantize_per_tensor_default_52 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_52, 0.050029464066028595, 18, -128, 127, torch.int8);  quantize_per_tensor_default_52 = None\n",
      "    features_10_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"10\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_28 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_52, dequantize_per_channel_default_28, features_10_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 384);  dequantize_per_tensor_default_52 = dequantize_per_channel_default_28 = features_10_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_53 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_28, 0.09310118108987808, 62, -128, 127, torch.int8);  conv2d_28 = None\n",
      "    dequantize_per_tensor_default_53 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_53, 0.09310118108987808, 62, -128, 127, torch.int8);  quantize_per_tensor_default_53 = None\n",
      "    hardtanh__19 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_53, 0.0, 6.0);  dequantize_per_tensor_default_53 = None\n",
      "    quantize_per_tensor_default_54 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__19, 0.09310118108987808, 62, -128, 127, torch.int8);  hardtanh__19 = None\n",
      "    dequantize_per_tensor_default_54 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_54, 0.09310118108987808, 62, -128, 127, torch.int8);  quantize_per_tensor_default_54 = None\n",
      "    features_10_conv_2_weight_bias = getattr(getattr(self.features, \"10\").conv, \"2\").weight_bias\n",
      "    conv2d_29 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_54, dequantize_per_channel_default_29, features_10_conv_2_weight_bias);  dequantize_per_tensor_default_54 = dequantize_per_channel_default_29 = features_10_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_55 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_29, 0.12139638513326645, -15, -128, 127, torch.int8);  conv2d_29 = None\n",
      "    dequantize_per_tensor_default_55 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_55, 0.12139638513326645, -15, -128, 127, torch.int8);  quantize_per_tensor_default_55 = None\n",
      "    add_5 = torch.ops.aten.add.Tensor(add_4, dequantize_per_tensor_default_55);  add_4 = dequantize_per_tensor_default_55 = None\n",
      "    quantize_per_tensor_default_56 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_5, 0.14760500192642212, -20, -128, 127, torch.int8);  add_5 = None\n",
      "    dequantize_per_tensor_default_56 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_56, 0.14760500192642212, -20, -128, 127, torch.int8);  quantize_per_tensor_default_56 = None\n",
      "    features_11_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"11\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_30 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_56, dequantize_per_channel_default_30, features_11_conv_0_0_weight_bias);  dequantize_per_tensor_default_56 = dequantize_per_channel_default_30 = features_11_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_57 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_30, 0.046598777174949646, 10, -128, 127, torch.int8);  conv2d_30 = None\n",
      "    dequantize_per_tensor_default_57 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_57, 0.046598777174949646, 10, -128, 127, torch.int8);  quantize_per_tensor_default_57 = None\n",
      "    hardtanh__20 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_57, 0.0, 6.0);  dequantize_per_tensor_default_57 = None\n",
      "    quantize_per_tensor_default_58 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__20, 0.046598777174949646, 10, -128, 127, torch.int8);  hardtanh__20 = None\n",
      "    dequantize_per_tensor_default_58 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_58, 0.046598777174949646, 10, -128, 127, torch.int8);  quantize_per_tensor_default_58 = None\n",
      "    features_11_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"11\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_31 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_58, dequantize_per_channel_default_31, features_11_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 384);  dequantize_per_tensor_default_58 = dequantize_per_channel_default_31 = features_11_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_59 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_31, 0.04767346382141113, 0, -128, 127, torch.int8);  conv2d_31 = None\n",
      "    dequantize_per_tensor_default_59 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_59, 0.04767346382141113, 0, -128, 127, torch.int8);  quantize_per_tensor_default_59 = None\n",
      "    hardtanh__21 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_59, 0.0, 6.0);  dequantize_per_tensor_default_59 = None\n",
      "    quantize_per_tensor_default_60 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__21, 0.04767346382141113, 0, -128, 127, torch.int8);  hardtanh__21 = None\n",
      "    dequantize_per_tensor_default_60 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_60, 0.04767346382141113, 0, -128, 127, torch.int8);  quantize_per_tensor_default_60 = None\n",
      "    features_11_conv_2_weight_bias = getattr(getattr(self.features, \"11\").conv, \"2\").weight_bias\n",
      "    conv2d_32 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_60, dequantize_per_channel_default_32, features_11_conv_2_weight_bias);  dequantize_per_tensor_default_60 = dequantize_per_channel_default_32 = features_11_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_61 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_32, 0.07938653975725174, 4, -128, 127, torch.int8);  conv2d_32 = None\n",
      "    dequantize_per_tensor_default_61 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_61, 0.07938653975725174, 4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_105 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_61, 0.07938653975725174, 4, -128, 127, torch.int8);  quantize_per_tensor_default_61 = None\n",
      "    features_12_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"12\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_33 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_105, dequantize_per_channel_default_33, features_12_conv_0_0_weight_bias);  dequantize_per_tensor_default_105 = dequantize_per_channel_default_33 = features_12_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_62 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_33, 0.028747810050845146, 4, -128, 127, torch.int8);  conv2d_33 = None\n",
      "    dequantize_per_tensor_default_62 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_62, 0.028747810050845146, 4, -128, 127, torch.int8);  quantize_per_tensor_default_62 = None\n",
      "    hardtanh__22 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_62, 0.0, 6.0);  dequantize_per_tensor_default_62 = None\n",
      "    quantize_per_tensor_default_63 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__22, 0.028747810050845146, 4, -128, 127, torch.int8);  hardtanh__22 = None\n",
      "    dequantize_per_tensor_default_63 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_63, 0.028747810050845146, 4, -128, 127, torch.int8);  quantize_per_tensor_default_63 = None\n",
      "    features_12_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"12\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_34 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_63, dequantize_per_channel_default_34, features_12_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 576);  dequantize_per_tensor_default_63 = dequantize_per_channel_default_34 = features_12_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_64 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_34, 0.05448530241847038, 22, -128, 127, torch.int8);  conv2d_34 = None\n",
      "    dequantize_per_tensor_default_64 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_64, 0.05448530241847038, 22, -128, 127, torch.int8);  quantize_per_tensor_default_64 = None\n",
      "    hardtanh__23 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_64, 0.0, 6.0);  dequantize_per_tensor_default_64 = None\n",
      "    quantize_per_tensor_default_65 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__23, 0.05448530241847038, 22, -128, 127, torch.int8);  hardtanh__23 = None\n",
      "    dequantize_per_tensor_default_65 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_65, 0.05448530241847038, 22, -128, 127, torch.int8);  quantize_per_tensor_default_65 = None\n",
      "    features_12_conv_2_weight_bias = getattr(getattr(self.features, \"12\").conv, \"2\").weight_bias\n",
      "    conv2d_35 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_65, dequantize_per_channel_default_35, features_12_conv_2_weight_bias);  dequantize_per_tensor_default_65 = dequantize_per_channel_default_35 = features_12_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_66 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_35, 0.05452864617109299, 10, -128, 127, torch.int8);  conv2d_35 = None\n",
      "    dequantize_per_tensor_default_66 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_66, 0.05452864617109299, 10, -128, 127, torch.int8);  quantize_per_tensor_default_66 = None\n",
      "    add_6 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_61, dequantize_per_tensor_default_66);  dequantize_per_tensor_default_61 = dequantize_per_tensor_default_66 = None\n",
      "    quantize_per_tensor_default_67 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_6, 0.09187797456979752, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_67 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_67, 0.09187797456979752, 6, -128, 127, torch.int8);  quantize_per_tensor_default_67 = None\n",
      "    features_13_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"13\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_36 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_67, dequantize_per_channel_default_36, features_13_conv_0_0_weight_bias);  dequantize_per_tensor_default_67 = dequantize_per_channel_default_36 = features_13_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_68 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_36, 0.02842160500586033, 9, -128, 127, torch.int8);  conv2d_36 = None\n",
      "    dequantize_per_tensor_default_68 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_68, 0.02842160500586033, 9, -128, 127, torch.int8);  quantize_per_tensor_default_68 = None\n",
      "    hardtanh__24 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_68, 0.0, 6.0);  dequantize_per_tensor_default_68 = None\n",
      "    quantize_per_tensor_default_69 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__24, 0.02842160500586033, 9, -128, 127, torch.int8);  hardtanh__24 = None\n",
      "    dequantize_per_tensor_default_69 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_69, 0.02842160500586033, 9, -128, 127, torch.int8);  quantize_per_tensor_default_69 = None\n",
      "    features_13_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"13\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_37 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_69, dequantize_per_channel_default_37, features_13_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 576);  dequantize_per_tensor_default_69 = dequantize_per_channel_default_37 = features_13_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_70 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_37, 0.06048448756337166, 44, -128, 127, torch.int8);  conv2d_37 = None\n",
      "    dequantize_per_tensor_default_70 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_70, 0.06048448756337166, 44, -128, 127, torch.int8);  quantize_per_tensor_default_70 = None\n",
      "    hardtanh__25 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_70, 0.0, 6.0);  dequantize_per_tensor_default_70 = None\n",
      "    quantize_per_tensor_default_71 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__25, 0.06048448756337166, 44, -128, 127, torch.int8);  hardtanh__25 = None\n",
      "    dequantize_per_tensor_default_71 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_71, 0.06048448756337166, 44, -128, 127, torch.int8);  quantize_per_tensor_default_71 = None\n",
      "    features_13_conv_2_weight_bias = getattr(getattr(self.features, \"13\").conv, \"2\").weight_bias\n",
      "    conv2d_38 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_71, dequantize_per_channel_default_38, features_13_conv_2_weight_bias);  dequantize_per_tensor_default_71 = dequantize_per_channel_default_38 = features_13_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_72 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_38, 0.06608446687459946, 15, -128, 127, torch.int8);  conv2d_38 = None\n",
      "    dequantize_per_tensor_default_72 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_72, 0.06608446687459946, 15, -128, 127, torch.int8);  quantize_per_tensor_default_72 = None\n",
      "    add_7 = torch.ops.aten.add.Tensor(add_6, dequantize_per_tensor_default_72);  add_6 = dequantize_per_tensor_default_72 = None\n",
      "    quantize_per_tensor_default_73 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_7, 0.11169695854187012, 0, -128, 127, torch.int8);  add_7 = None\n",
      "    dequantize_per_tensor_default_73 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_73, 0.11169695854187012, 0, -128, 127, torch.int8);  quantize_per_tensor_default_73 = None\n",
      "    features_14_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"14\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_39 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_73, dequantize_per_channel_default_39, features_14_conv_0_0_weight_bias);  dequantize_per_tensor_default_73 = dequantize_per_channel_default_39 = features_14_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_74 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_39, 0.03513330966234207, 13, -128, 127, torch.int8);  conv2d_39 = None\n",
      "    dequantize_per_tensor_default_74 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_74, 0.03513330966234207, 13, -128, 127, torch.int8);  quantize_per_tensor_default_74 = None\n",
      "    hardtanh__26 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_74, 0.0, 6.0);  dequantize_per_tensor_default_74 = None\n",
      "    quantize_per_tensor_default_75 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__26, 0.03513330966234207, 13, -128, 127, torch.int8);  hardtanh__26 = None\n",
      "    dequantize_per_tensor_default_75 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_75, 0.03513330966234207, 13, -128, 127, torch.int8);  quantize_per_tensor_default_75 = None\n",
      "    features_14_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"14\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_40 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_75, dequantize_per_channel_default_40, features_14_conv_1_0_weight_bias, [2, 2], [1, 1], [1, 1], 576);  dequantize_per_tensor_default_75 = dequantize_per_channel_default_40 = features_14_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_76 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_40, 0.03605400025844574, -22, -128, 127, torch.int8);  conv2d_40 = None\n",
      "    dequantize_per_tensor_default_76 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_76, 0.03605400025844574, -22, -128, 127, torch.int8);  quantize_per_tensor_default_76 = None\n",
      "    hardtanh__27 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_76, 0.0, 6.0);  dequantize_per_tensor_default_76 = None\n",
      "    quantize_per_tensor_default_77 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__27, 0.03605400025844574, -22, -128, 127, torch.int8);  hardtanh__27 = None\n",
      "    dequantize_per_tensor_default_77 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_77, 0.03605400025844574, -22, -128, 127, torch.int8);  quantize_per_tensor_default_77 = None\n",
      "    features_14_conv_2_weight_bias = getattr(getattr(self.features, \"14\").conv, \"2\").weight_bias\n",
      "    conv2d_41 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_77, dequantize_per_channel_default_41, features_14_conv_2_weight_bias);  dequantize_per_tensor_default_77 = dequantize_per_channel_default_41 = features_14_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_78 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_41, 0.06095806509256363, -3, -128, 127, torch.int8);  conv2d_41 = None\n",
      "    dequantize_per_tensor_default_78 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_78, 0.06095806509256363, -3, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_106 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_78, 0.06095806509256363, -3, -128, 127, torch.int8);  quantize_per_tensor_default_78 = None\n",
      "    features_15_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"15\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_42 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_106, dequantize_per_channel_default_42, features_15_conv_0_0_weight_bias);  dequantize_per_tensor_default_106 = dequantize_per_channel_default_42 = features_15_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_79 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_42, 0.027046846225857735, -2, -128, 127, torch.int8);  conv2d_42 = None\n",
      "    dequantize_per_tensor_default_79 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_79, 0.027046846225857735, -2, -128, 127, torch.int8);  quantize_per_tensor_default_79 = None\n",
      "    hardtanh__28 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_79, 0.0, 6.0);  dequantize_per_tensor_default_79 = None\n",
      "    quantize_per_tensor_default_80 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__28, 0.027046846225857735, -2, -128, 127, torch.int8);  hardtanh__28 = None\n",
      "    dequantize_per_tensor_default_80 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_80, 0.027046846225857735, -2, -128, 127, torch.int8);  quantize_per_tensor_default_80 = None\n",
      "    features_15_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"15\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_43 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_80, dequantize_per_channel_default_43, features_15_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 960);  dequantize_per_tensor_default_80 = dequantize_per_channel_default_43 = features_15_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_81 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_43, 0.06016433611512184, 20, -128, 127, torch.int8);  conv2d_43 = None\n",
      "    dequantize_per_tensor_default_81 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_81, 0.06016433611512184, 20, -128, 127, torch.int8);  quantize_per_tensor_default_81 = None\n",
      "    hardtanh__29 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_81, 0.0, 6.0);  dequantize_per_tensor_default_81 = None\n",
      "    quantize_per_tensor_default_82 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__29, 0.06016433611512184, 20, -128, 127, torch.int8);  hardtanh__29 = None\n",
      "    dequantize_per_tensor_default_82 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_82, 0.06016433611512184, 20, -128, 127, torch.int8);  quantize_per_tensor_default_82 = None\n",
      "    features_15_conv_2_weight_bias = getattr(getattr(self.features, \"15\").conv, \"2\").weight_bias\n",
      "    conv2d_44 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_82, dequantize_per_channel_default_44, features_15_conv_2_weight_bias);  dequantize_per_tensor_default_82 = dequantize_per_channel_default_44 = features_15_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_83 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_44, 0.09400313347578049, 2, -128, 127, torch.int8);  conv2d_44 = None\n",
      "    dequantize_per_tensor_default_83 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_83, 0.09400313347578049, 2, -128, 127, torch.int8);  quantize_per_tensor_default_83 = None\n",
      "    add_8 = torch.ops.aten.add.Tensor(dequantize_per_tensor_default_78, dequantize_per_tensor_default_83);  dequantize_per_tensor_default_78 = dequantize_per_tensor_default_83 = None\n",
      "    quantize_per_tensor_default_84 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_8, 0.10241571813821793, 23, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_84 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_84, 0.10241571813821793, 23, -128, 127, torch.int8);  quantize_per_tensor_default_84 = None\n",
      "    features_16_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"16\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_45 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_84, dequantize_per_channel_default_45, features_16_conv_0_0_weight_bias);  dequantize_per_tensor_default_84 = dequantize_per_channel_default_45 = features_16_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_85 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_45, 0.04639780521392822, -10, -128, 127, torch.int8);  conv2d_45 = None\n",
      "    dequantize_per_tensor_default_85 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_85, 0.04639780521392822, -10, -128, 127, torch.int8);  quantize_per_tensor_default_85 = None\n",
      "    hardtanh__30 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_85, 0.0, 6.0);  dequantize_per_tensor_default_85 = None\n",
      "    quantize_per_tensor_default_86 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__30, 0.04639780521392822, -10, -128, 127, torch.int8);  hardtanh__30 = None\n",
      "    dequantize_per_tensor_default_86 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_86, 0.04639780521392822, -10, -128, 127, torch.int8);  quantize_per_tensor_default_86 = None\n",
      "    features_16_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"16\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_46 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_86, dequantize_per_channel_default_46, features_16_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 960);  dequantize_per_tensor_default_86 = dequantize_per_channel_default_46 = features_16_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_87 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_46, 0.08798554539680481, 67, -128, 127, torch.int8);  conv2d_46 = None\n",
      "    dequantize_per_tensor_default_87 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_87, 0.08798554539680481, 67, -128, 127, torch.int8);  quantize_per_tensor_default_87 = None\n",
      "    hardtanh__31 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_87, 0.0, 6.0);  dequantize_per_tensor_default_87 = None\n",
      "    quantize_per_tensor_default_88 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__31, 0.08798554539680481, 67, -128, 127, torch.int8);  hardtanh__31 = None\n",
      "    dequantize_per_tensor_default_88 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_88, 0.08798554539680481, 67, -128, 127, torch.int8);  quantize_per_tensor_default_88 = None\n",
      "    features_16_conv_2_weight_bias = getattr(getattr(self.features, \"16\").conv, \"2\").weight_bias\n",
      "    conv2d_47 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_88, dequantize_per_channel_default_47, features_16_conv_2_weight_bias);  dequantize_per_tensor_default_88 = dequantize_per_channel_default_47 = features_16_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_89 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_47, 0.08014596998691559, -1, -128, 127, torch.int8);  conv2d_47 = None\n",
      "    dequantize_per_tensor_default_89 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_89, 0.08014596998691559, -1, -128, 127, torch.int8);  quantize_per_tensor_default_89 = None\n",
      "    add_9 = torch.ops.aten.add.Tensor(add_8, dequantize_per_tensor_default_89);  add_8 = dequantize_per_tensor_default_89 = None\n",
      "    quantize_per_tensor_default_90 = torch.ops.quantized_decomposed.quantize_per_tensor.default(add_9, 0.15459498763084412, 10, -128, 127, torch.int8);  add_9 = None\n",
      "    dequantize_per_tensor_default_90 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_90, 0.15459498763084412, 10, -128, 127, torch.int8);  quantize_per_tensor_default_90 = None\n",
      "    features_17_conv_0_0_weight_bias = getattr(getattr(getattr(self.features, \"17\").conv, \"0\"), \"0\").weight_bias\n",
      "    conv2d_48 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_90, dequantize_per_channel_default_48, features_17_conv_0_0_weight_bias);  dequantize_per_tensor_default_90 = dequantize_per_channel_default_48 = features_17_conv_0_0_weight_bias = None\n",
      "    quantize_per_tensor_default_91 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_48, 0.047592151910066605, -9, -128, 127, torch.int8);  conv2d_48 = None\n",
      "    dequantize_per_tensor_default_91 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_91, 0.047592151910066605, -9, -128, 127, torch.int8);  quantize_per_tensor_default_91 = None\n",
      "    hardtanh__32 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_91, 0.0, 6.0);  dequantize_per_tensor_default_91 = None\n",
      "    quantize_per_tensor_default_92 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__32, 0.047592151910066605, -9, -128, 127, torch.int8);  hardtanh__32 = None\n",
      "    dequantize_per_tensor_default_92 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_92, 0.047592151910066605, -9, -128, 127, torch.int8);  quantize_per_tensor_default_92 = None\n",
      "    features_17_conv_1_0_weight_bias = getattr(getattr(getattr(self.features, \"17\").conv, \"1\"), \"0\").weight_bias\n",
      "    conv2d_49 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_92, dequantize_per_channel_default_49, features_17_conv_1_0_weight_bias, [1, 1], [1, 1], [1, 1], 960);  dequantize_per_tensor_default_92 = dequantize_per_channel_default_49 = features_17_conv_1_0_weight_bias = None\n",
      "    quantize_per_tensor_default_93 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_49, 0.08663517236709595, 27, -128, 127, torch.int8);  conv2d_49 = None\n",
      "    dequantize_per_tensor_default_93 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_93, 0.08663517236709595, 27, -128, 127, torch.int8);  quantize_per_tensor_default_93 = None\n",
      "    hardtanh__33 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_93, 0.0, 6.0);  dequantize_per_tensor_default_93 = None\n",
      "    quantize_per_tensor_default_94 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__33, 0.08663517236709595, 27, -128, 127, torch.int8);  hardtanh__33 = None\n",
      "    dequantize_per_tensor_default_94 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_94, 0.08663517236709595, 27, -128, 127, torch.int8);  quantize_per_tensor_default_94 = None\n",
      "    features_17_conv_2_weight_bias = getattr(getattr(self.features, \"17\").conv, \"2\").weight_bias\n",
      "    conv2d_50 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_94, dequantize_per_channel_default_50, features_17_conv_2_weight_bias);  dequantize_per_tensor_default_94 = dequantize_per_channel_default_50 = features_17_conv_2_weight_bias = None\n",
      "    quantize_per_tensor_default_95 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_50, 0.05935077369213104, -5, -128, 127, torch.int8);  conv2d_50 = None\n",
      "    dequantize_per_tensor_default_95 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_95, 0.05935077369213104, -5, -128, 127, torch.int8);  quantize_per_tensor_default_95 = None\n",
      "    features_18_0_weight_bias = getattr(getattr(self.features, \"18\"), \"0\").weight_bias\n",
      "    conv2d_51 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_95, dequantize_per_channel_default_51, features_18_0_weight_bias);  dequantize_per_tensor_default_95 = dequantize_per_channel_default_51 = features_18_0_weight_bias = None\n",
      "    quantize_per_tensor_default_96 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_51, 0.08606801927089691, 39, -128, 127, torch.int8);  conv2d_51 = None\n",
      "    dequantize_per_tensor_default_96 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_96, 0.08606801927089691, 39, -128, 127, torch.int8);  quantize_per_tensor_default_96 = None\n",
      "    hardtanh__34 = torch.ops.aten.hardtanh_.default(dequantize_per_tensor_default_96, 0.0, 6.0);  dequantize_per_tensor_default_96 = None\n",
      "    quantize_per_tensor_default_97 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh__34, 0.08606801927089691, 39, -128, 127, torch.int8);  hardtanh__34 = None\n",
      "    dequantize_per_tensor_default_97 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_97, 0.08606801927089691, 39, -128, 127, torch.int8);  quantize_per_tensor_default_97 = None\n",
      "    adaptive_avg_pool2d = torch.ops.aten.adaptive_avg_pool2d.default(dequantize_per_tensor_default_97, [1, 1]);  dequantize_per_tensor_default_97 = None\n",
      "    quantize_per_tensor_default_98 = torch.ops.quantized_decomposed.quantize_per_tensor.default(adaptive_avg_pool2d, 0.08606801927089691, 39, -128, 127, torch.int8);  adaptive_avg_pool2d = None\n",
      "    dequantize_per_tensor_default_98 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_98, 0.08606801927089691, 39, -128, 127, torch.int8);  quantize_per_tensor_default_98 = None\n",
      "    flatten = torch.ops.aten.flatten.using_ints(dequantize_per_tensor_default_98, 1);  dequantize_per_tensor_default_98 = None\n",
      "    quantize_per_tensor_default_99 = torch.ops.quantized_decomposed.quantize_per_tensor.default(flatten, 0.08606801927089691, 39, -128, 127, torch.int8);  flatten = None\n",
      "    dequantize_per_tensor_default_99 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_99, 0.08606801927089691, 39, -128, 127, torch.int8);  quantize_per_tensor_default_99 = None\n",
      "    dropout = torch.ops.aten.dropout.default(dequantize_per_tensor_default_99, 0.2, False);  dequantize_per_tensor_default_99 = None\n",
      "    quantize_per_tensor_default_100 = torch.ops.quantized_decomposed.quantize_per_tensor.default(dropout, 0.014248741790652275, -128, -128, 127, torch.int8);  dropout = None\n",
      "    dequantize_per_tensor_default_100 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_100, 0.014248741790652275, -128, -128, 127, torch.int8);  quantize_per_tensor_default_100 = None\n",
      "    linear = torch.ops.aten.linear.default(dequantize_per_tensor_default_100, dequantize_per_channel_default_52, classifier_1_bias);  dequantize_per_tensor_default_100 = dequantize_per_channel_default_52 = classifier_1_bias = None\n",
      "    quantize_per_tensor_default_101 = torch.ops.quantized_decomposed.quantize_per_tensor.default(linear, 0.022447125986218452, -61, -128, 127, torch.int8);  linear = None\n",
      "    dequantize_per_tensor_default_101 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_101, 0.022447125986218452, -61, -128, 127, torch.int8);  quantize_per_tensor_default_101 = None\n",
      "    return pytree.tree_unflatten((dequantize_per_tensor_default_101,), self._out_spec)\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1757303413.778856    6423 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1757303413.778882    6423 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "I0000 00:00:1757303413.779160    6423 reader.cc:83] Reading SavedModel from: /tmp/tmp6ohyr2g1\n",
      "I0000 00:00:1757303413.783841    6423 reader.cc:52] Reading meta graph with tags { serve }\n",
      "I0000 00:00:1757303413.783866    6423 reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmp6ohyr2g1\n",
      "I0000 00:00:1757303413.820058    6423 loader.cc:236] Restoring SavedModel bundle.\n",
      "I0000 00:00:1757303414.158779    6423 loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmp6ohyr2g1\n",
      "I0000 00:00:1757303414.245415    6423 loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 466282 microseconds.\n",
      "I0000 00:00:1757303415.540812    6423 flatbuffer_export.cc:4150] Estimated count of arithmetic ops: 608.445 M  ops, equivalently 304.223 M  MACs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
    "\n",
    "# PT2E (torch.ao)\n",
    "from torch.ao.quantization.quantize_pt2e import prepare_pt2e, convert_pt2e\n",
    "\n",
    "# AI Edge Torch\n",
    "import ai_edge_torch as aet\n",
    "from ai_edge_torch.quantize import pt2e_quantizer as aet_q\n",
    "from ai_edge_torch.quantize import quant_config as aet_qc\n",
    "\n",
    "m = mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT).eval()\n",
    "example_inputs = (torch.randn(1,3,224,224),)\n",
    "\n",
    "# 1) Capture to ExportedProgram (ATen graph)\n",
    "ep = torch.export.export(m, example_inputs).module()  # 2.6+ API\n",
    "\n",
    "# 2) Configure an AET PT2E quantizer (symmetric, per-channel)\n",
    "qspec = aet_q.get_symmetric_quantization_config(is_per_channel=True)\n",
    "quantizer = aet_q.PT2EQuantizer().set_global(qspec)\n",
    "\n",
    "# 3) Prepare + calibrate\n",
    "prepared = prepare_pt2e(ep, quantizer)\n",
    "with torch.no_grad():\n",
    "    for _ in range(32): prepared(torch.randn(1,3,224,224))\n",
    "\n",
    "# 4) Convert (keep Q/DQ explicit for TFLite lowering)\n",
    "quantized = convert_pt2e(prepared, fold_quantize=False)\n",
    "\n",
    "print(quantized)\n",
    "\n",
    "# 5) Convert to TFLite\n",
    "edge_model = aet.convert(\n",
    "    quantized,\n",
    "    example_inputs,\n",
    "    quant_config=aet_qc.QuantConfig(pt2e_quantizer=quantizer),\n",
    ")\n",
    "edge_model.export(\"mobilenetv2_int8.tflite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf000232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': np.float32(0.011216138), 'cosine': np.float32(0.9931354), 'top1_agree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1) Prepare one test input (use real, normalized data if possible)\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "with torch.no_grad():\n",
    "    y_fp = m.eval()(x).cpu().numpy()\n",
    "\n",
    "# 2) Run TFLite\n",
    "import tensorflow as tf  # or tflite_runtime.interpreter\n",
    "interpreter = tf.lite.Interpreter(model_path=\"mobilenetv2_int8.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "inp = interpreter.get_input_details()[0]\n",
    "out = interpreter.get_output_details()[0]\n",
    "\n",
    "x_np = x.cpu().numpy().astype(np.float32)\n",
    "\n",
    "# Handle quantized or float I/O automatically\n",
    "def set_input(interpreter, detail, x_float):\n",
    "    if np.issubdtype(detail[\"dtype\"], np.floating):\n",
    "        interpreter.set_tensor(detail[\"index\"], x_float)\n",
    "    else:\n",
    "        scale, zero = detail[\"quantization\"]\n",
    "        x_q = np.round(x_float / scale + zero)\n",
    "        qmin = np.iinfo(detail[\"dtype\"]).min\n",
    "        qmax = np.iinfo(detail[\"dtype\"]).max\n",
    "        x_q = np.clip(x_q, qmin, qmax).astype(detail[\"dtype\"])\n",
    "        interpreter.set_tensor(detail[\"index\"], x_q)\n",
    "\n",
    "def get_output(interpreter, detail):\n",
    "    y = interpreter.get_tensor(detail[\"index\"])\n",
    "    if not np.issubdtype(detail[\"dtype\"], np.floating):\n",
    "        scale, zero = detail[\"quantization\"]\n",
    "        y = (y.astype(np.float32) - zero) * scale\n",
    "    return y\n",
    "\n",
    "set_input(interpreter, inp, x_np)\n",
    "interpreter.invoke()\n",
    "y_tfl = get_output(interpreter, out)\n",
    "\n",
    "# 3) Metrics (PyTorch vs TFLite)\n",
    "mse = np.mean((y_fp - y_tfl) ** 2)\n",
    "cos = np.mean(np.sum(y_fp * y_tfl, axis=1) /\n",
    "              (np.linalg.norm(y_fp, axis=1) * np.linalg.norm(y_tfl, axis=1) + 1e-12))\n",
    "top1_pt  = y_fp.argmax(axis=1)\n",
    "top1_tfl = y_tfl.argmax(axis=1)\n",
    "agree = float((top1_pt == top1_tfl).mean())\n",
    "\n",
    "print({\"mse\": mse, \"cosine\": cos, \"top1_agree\": agree})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
